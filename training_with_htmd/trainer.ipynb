{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (2596, 24, 24, 24, 16) (649, 24, 24, 24, 16) (271, 24, 24, 24, 16)\n",
      "WARNING:tensorflow:From /Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abdulsalamyazid/opt/miniconda3/envs/h/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, Add, merge, concatenate\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.pooling import MaxPooling3D, GlobalAveragePooling3D, AveragePooling3D\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import he_uniform\n",
    "from keras.initializers import glorot_uniform\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from generators import DataGenerator, AugmentedDataGenerator\n",
    "from models import Squeeze_model\n",
    "\n",
    "data_dir = \"../dataset\"\n",
    "\n",
    "nb_batch =32\n",
    "nb_epochs = 1\n",
    "l_rate=1e-4\n",
    "augmented=False\n",
    "multi_gpu=0\n",
    "\n",
    "  # Load the data\n",
    "h5f = h5py.File(os.path.join(data_dir, \"data.h5\"), 'r')\n",
    "train_x, train_y = h5f['train_x'][:], h5f['train_y'][:]\n",
    "valid_x, valid_y = h5f['valid_x'][:], h5f['valid_y'][:]\n",
    "test_x, test_y = h5f['test_x'][:], h5f['test_y'][:]\n",
    "h5f.close()\n",
    "\n",
    "print(\"Data shapes: \", train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "# Training parameters\n",
    "if multi_gpu : nb_batch = multi_gpu*nb_batch # Assigning same batch size to all the gpus\n",
    "\n",
    "# Build the model \n",
    "model_input = Input(shape=(24, 24, 24, 16))\n",
    "model = Model(inputs=model_input, outputs=Squeeze_model(model_input))\n",
    "\n",
    "if multi_gpu: model = multi_gpu_model(model, gpus=multi_gpu)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizers.adam(lr=l_rate, beta_1=0.99, beta_2=0.999),\n",
    "            loss='mean_squared_error')\n",
    "\n",
    "# checkpoint\n",
    "outputFolder = \"weights\"\n",
    "if not os.path.isdir(outputFolder): os.makedirs(outputFolder)\n",
    "weigts_filepath = os.path.join(outputFolder, \"weights.h5\")\n",
    "callbacks_list = [ModelCheckpoint(weigts_filepath, \n",
    "                                monitor='val_loss',\n",
    "                                verbose=1,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True,\n",
    "                                mode='auto', period=1)]\n",
    "\n",
    "  # Train without generators\n",
    "  # history = model.fit(x=train_x, y=train_y, \n",
    "  #                     batch_size=nb_batch, \n",
    "  #                     epochs=nb_epochs, \n",
    "  #                     callbacks=callbacks_list, \n",
    "  #                     validation_data=(valid_x, valid_y), \n",
    "  #                     verbose=True)\n",
    "\n",
    "\n",
    "  # Generators\n",
    "if augmented:\n",
    "    print(\"TRINING ON AUGMENTED DATA\")\n",
    "    data_gen = AugmentedDataGenerator(x=train_x, y=train_y, batch_size=nb_batch)\n",
    "    val_gen = AugmentedDataGenerator(x=valid_x, y=valid_y, batch_size=nb_batch)\n",
    "else:\n",
    "    data_gen = DataGenerator(x=train_x, y=train_y, batch_size=nb_batch)\n",
    "    val_gen = DataGenerator(x=valid_x, y=valid_y, batch_size=nb_batch)\n",
    "\n",
    "# Train\n",
    "history = model.fit_generator(generator=data_gen, validation_data=val_gen,\n",
    "                            use_multiprocessing=False, \n",
    "                            epochs=nb_epochs, \n",
    "                            max_queue_size=10, \n",
    "                            workers=56, \n",
    "                            verbose=1, \n",
    "                            callbacks=callbacks_list)\n",
    "\n",
    "  # Plot training history\n",
    "  #plt.figure()\n",
    "  #plt.plot(history['loss'])\n",
    "  #plt.plot(history['val_loss'])\n",
    "  #plt.xlabel(\"Epochs\")\n",
    "  #plt.ylabel(\"Loss (MSE)\")\n",
    "  #plt.legend(['Train Loss', 'Validation Loss'])\n",
    "  #plt.savefig('training_history.png', format='png', dpi=1000)\n",
    "  #plt.show()\n",
    "\n",
    "# Load the best weights\n",
    "#model.load_weights(weigts_filepath)\n",
    "\n",
    "\n",
    "# Evaluate the model's performance\n",
    "train_r2 = r2_score(y_true=train_y, y_pred=model.predict(train_x))\n",
    "print(\"Train r2: \", train_r2)\n",
    "\n",
    "test_r2 = r2_score(y_true=test_y, y_pred=model.predict(test_x))\n",
    "print(\"Test r2: \", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "trained-reunion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights/weights.h5'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigts_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-claim",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
